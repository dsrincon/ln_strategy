{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LN - Data PP - Stability and efficiency calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import itertools\n",
    "#import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import io\n",
    "from itertools import islice\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from time import sleep\n",
    "\n",
    "from dask_cloudprovider import FargateCluster\n",
    "from dask.distributed import Client\n",
    "import dask.array as da\n",
    "import dask\n",
    "\n",
    "import s3fs\n",
    "\n",
    "import boto3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load Data\n",
    "\n",
    "# Initiate s3 resource\n",
    "\n",
    "session = boto3.session.Session()\n",
    "s3 = session.resource('s3')\n",
    "\n",
    "\n",
    "# Dataframe\n",
    "\n",
    "decisions_load = s3.Object(bucket_name='ln-strategy-data', key='LN_channels.csv').get()\n",
    "decisions_df=pd.read_csv(io.BytesIO(decisions_load['Body'].read()))\n",
    "\n",
    "# Channel closures\n",
    "closure_file = s3.Object(bucket_name='ln-strategy-data', key='channel_closures.p').get()\n",
    "channel_closures = pickle.loads(closure_file['Body'].read())\n",
    "    \n",
    "    \n",
    "# Channel openings \n",
    "opens_file = s3.Object(bucket_name='ln-strategy-data', key='channel_opens.p').get()\n",
    "channel_opens = pickle.loads(opens_file['Body'].read())\n",
    "\n",
    "    \n",
    "\n",
    "# Create list with graph keys\n",
    "\n",
    "#TODO: Save graphs as numpy array in single H5 file to reduce. Test if creating graphs takes longer than reading from S3\n",
    "\n",
    "# graph_dir='./data/graph_snapshots' - For local tests\n",
    "extraction_id=1585344554\n",
    "graph_keys = [obj.key \n",
    "        for obj in s3.Bucket(name='ln-strategy-data').objects.all()\n",
    "        if re.match(\".*\"+str(extraction_id)+\"_connected/.*\\.gpickle\",obj.key)]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: extracted formats\n",
    "print(\"---Sample graph keys---\")\n",
    "print(graph_keys[0])\n",
    "print(\"---Sample channel opens---\")\n",
    "print(channel_opens[513675])\n",
    "print(\"---Sample channel closures---\")\n",
    "print(channel_closures[592638])\n",
    "print(\"----Sample blocks----\")\n",
    "print(blocks[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_channel_id</th>\n",
       "      <th>open_block</th>\n",
       "      <th>open_transaction</th>\n",
       "      <th>address</th>\n",
       "      <th>close_block</th>\n",
       "      <th>close_transaction</th>\n",
       "      <th>node0</th>\n",
       "      <th>node1</th>\n",
       "      <th>satoshis</th>\n",
       "      <th>last_seen</th>\n",
       "      <th>...</th>\n",
       "      <th>close_time</th>\n",
       "      <th>close_fee</th>\n",
       "      <th>last_update</th>\n",
       "      <th>close_type</th>\n",
       "      <th>close_htlc_count</th>\n",
       "      <th>close_balance_a</th>\n",
       "      <th>close_balance_b</th>\n",
       "      <th>dec_id</th>\n",
       "      <th>node0_id</th>\n",
       "      <th>node1_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>505149x622x0</td>\n",
       "      <td>505149</td>\n",
       "      <td>f6bc767df9148ebf76d2b9baf4eb46e3230712c2bf5a51...</td>\n",
       "      <td>bc1qjmg6ev344fenh3zhg0yjl6hyvxpxluw6x9nn2a5lv4...</td>\n",
       "      <td>592638.0</td>\n",
       "      <td>82cb2ea2a06c8c453d8b9ca08e17bbefe87225aa380b2d...</td>\n",
       "      <td>0250373555232cec757ea141273e75381c84cc3ab22f1e...</td>\n",
       "      <td>02ef61a252f9504a42fc264a28476f44cea0711a44b2da...</td>\n",
       "      <td>300000</td>\n",
       "      <td>2019-08-22 02:49:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.567276e+09</td>\n",
       "      <td>184.0</td>\n",
       "      <td>1.563172e+09</td>\n",
       "      <td>mutual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3570.0</td>\n",
       "      <td>296246.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3098</td>\n",
       "      <td>1492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>513675x2245x0</td>\n",
       "      <td>513675</td>\n",
       "      <td>4297b5fe9beeb701c67fd0f84861b22edbcafe5c25be67...</td>\n",
       "      <td>bc1qymmdt0vzhdjqyqw2cevrqppp6rrlg5j2l20yk72z6y...</td>\n",
       "      <td>594718.0</td>\n",
       "      <td>3f86d9427c750f37a963b5a329da8941520f5a6cdbfe02...</td>\n",
       "      <td>028aa5a991a2acf33da91674fe062219b640e5e57d77a4...</td>\n",
       "      <td>03fab7f8655169ea77d9691d4bd359e97782cb6177a6f7...</td>\n",
       "      <td>50000</td>\n",
       "      <td>2019-10-07 02:42:58</td>\n",
       "      <td>...</td>\n",
       "      <td>1.568401e+09</td>\n",
       "      <td>4410.0</td>\n",
       "      <td>1.552879e+09</td>\n",
       "      <td>unused</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45590.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5474</td>\n",
       "      <td>7365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>513887x1177x0</td>\n",
       "      <td>513887</td>\n",
       "      <td>3b4cc434e62c1739e79171c7c1641bf9ac0e32d8530c68...</td>\n",
       "      <td>bc1q48l3h7sfdjaqat3sy98naltkwlujwefwnkfqxfm8fd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02d97e94cfeedca2a3da47acb400bc6836e671b3cb3fc0...</td>\n",
       "      <td>03fab7f8655169ea77d9691d4bd359e97782cb6177a6f7...</td>\n",
       "      <td>50000</td>\n",
       "      <td>2020-02-14 03:15:22</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581536e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2797</td>\n",
       "      <td>7365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>513909x1248x0</td>\n",
       "      <td>513909</td>\n",
       "      <td>86311514680351b1e644276efd7704ba13be169cc1a272...</td>\n",
       "      <td>bc1q24kvd9wdjdhwgr54fmu7cu9xldmsjuwdsq2ph5fwnj...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02ad6fb8d693dc1e4569bcedefadf5f72a931ae027dc0f...</td>\n",
       "      <td>03fab7f8655169ea77d9691d4bd359e97782cb6177a6f7...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2020-02-14 03:15:26</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581464e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>211</td>\n",
       "      <td>7365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>513910x1814x1</td>\n",
       "      <td>513910</td>\n",
       "      <td>7f010765ce336d2be78c846844544e6a06ce2c59e7785f...</td>\n",
       "      <td>bc1qzh9xrpqvyse7fuanc8tl5e75qymq5fzk3deh78hs02...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02ad6fb8d693dc1e4569bcedefadf5f72a931ae027dc0f...</td>\n",
       "      <td>03fab7f8655169ea77d9691d4bd359e97782cb6177a6f7...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2020-02-14 03:15:26</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581466e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>211</td>\n",
       "      <td>7365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  short_channel_id  open_block  \\\n",
       "0     505149x622x0      505149   \n",
       "1    513675x2245x0      513675   \n",
       "2    513887x1177x0      513887   \n",
       "3    513909x1248x0      513909   \n",
       "4    513910x1814x1      513910   \n",
       "\n",
       "                                    open_transaction  \\\n",
       "0  f6bc767df9148ebf76d2b9baf4eb46e3230712c2bf5a51...   \n",
       "1  4297b5fe9beeb701c67fd0f84861b22edbcafe5c25be67...   \n",
       "2  3b4cc434e62c1739e79171c7c1641bf9ac0e32d8530c68...   \n",
       "3  86311514680351b1e644276efd7704ba13be169cc1a272...   \n",
       "4  7f010765ce336d2be78c846844544e6a06ce2c59e7785f...   \n",
       "\n",
       "                                             address  close_block  \\\n",
       "0  bc1qjmg6ev344fenh3zhg0yjl6hyvxpxluw6x9nn2a5lv4...     592638.0   \n",
       "1  bc1qymmdt0vzhdjqyqw2cevrqppp6rrlg5j2l20yk72z6y...     594718.0   \n",
       "2  bc1q48l3h7sfdjaqat3sy98naltkwlujwefwnkfqxfm8fd...          NaN   \n",
       "3  bc1q24kvd9wdjdhwgr54fmu7cu9xldmsjuwdsq2ph5fwnj...          NaN   \n",
       "4  bc1qzh9xrpqvyse7fuanc8tl5e75qymq5fzk3deh78hs02...          NaN   \n",
       "\n",
       "                                   close_transaction  \\\n",
       "0  82cb2ea2a06c8c453d8b9ca08e17bbefe87225aa380b2d...   \n",
       "1  3f86d9427c750f37a963b5a329da8941520f5a6cdbfe02...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                               node0  \\\n",
       "0  0250373555232cec757ea141273e75381c84cc3ab22f1e...   \n",
       "1  028aa5a991a2acf33da91674fe062219b640e5e57d77a4...   \n",
       "2  02d97e94cfeedca2a3da47acb400bc6836e671b3cb3fc0...   \n",
       "3  02ad6fb8d693dc1e4569bcedefadf5f72a931ae027dc0f...   \n",
       "4  02ad6fb8d693dc1e4569bcedefadf5f72a931ae027dc0f...   \n",
       "\n",
       "                                               node1  satoshis  \\\n",
       "0  02ef61a252f9504a42fc264a28476f44cea0711a44b2da...    300000   \n",
       "1  03fab7f8655169ea77d9691d4bd359e97782cb6177a6f7...     50000   \n",
       "2  03fab7f8655169ea77d9691d4bd359e97782cb6177a6f7...     50000   \n",
       "3  03fab7f8655169ea77d9691d4bd359e97782cb6177a6f7...     20000   \n",
       "4  03fab7f8655169ea77d9691d4bd359e97782cb6177a6f7...     20000   \n",
       "\n",
       "             last_seen  ...    close_time  close_fee   last_update  \\\n",
       "0  2019-08-22 02:49:00  ...  1.567276e+09      184.0  1.563172e+09   \n",
       "1  2019-10-07 02:42:58  ...  1.568401e+09     4410.0  1.552879e+09   \n",
       "2  2020-02-14 03:15:22  ...           NaN        NaN  1.581536e+09   \n",
       "3  2020-02-14 03:15:26  ...           NaN        NaN  1.581464e+09   \n",
       "4  2020-02-14 03:15:26  ...           NaN        NaN  1.581466e+09   \n",
       "\n",
       "   close_type  close_htlc_count close_balance_a  close_balance_b  dec_id  \\\n",
       "0      mutual               0.0          3570.0         296246.0       0   \n",
       "1      unused               0.0         45590.0              0.0       1   \n",
       "2         NaN               NaN             NaN              NaN       2   \n",
       "3         NaN               NaN             NaN              NaN       3   \n",
       "4         NaN               NaN             NaN              NaN       4   \n",
       "\n",
       "   node0_id  node1_id  \n",
       "0      3098      1492  \n",
       "1      5474      7365  \n",
       "2      2797      7365  \n",
       "3       211      7365  \n",
       "4       211      7365  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decisions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(decisions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection to AWS - Fargate Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = FargateCluster(n_workers=20,scheduler_timeout='60 minutes',image='dsrincon/dask-graph:nx-scipy-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e16a176ef53477ca75edb0dcbfdf95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>FargateCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n  â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/distributed/client.py:1079: VersionMismatchWarning: Mismatched versions found\n",
      "\n",
      "python\n",
      "+---------------------------+---------------+\n",
      "|                           | version       |\n",
      "+---------------------------+---------------+\n",
      "| client                    | 3.7.3.final.0 |\n",
      "| scheduler                 | 3.7.4.final.0 |\n",
      "| tcp://172.31.13.44:36759  | 3.7.4.final.0 |\n",
      "| tcp://172.31.14.120:36793 | 3.7.4.final.0 |\n",
      "| tcp://172.31.18.108:37605 | 3.7.4.final.0 |\n",
      "| tcp://172.31.20.181:45127 | 3.7.4.final.0 |\n",
      "| tcp://172.31.22.194:40509 | 3.7.4.final.0 |\n",
      "| tcp://172.31.32.143:46031 | 3.7.4.final.0 |\n",
      "| tcp://172.31.32.54:33291  | 3.7.4.final.0 |\n",
      "| tcp://172.31.33.144:43449 | 3.7.4.final.0 |\n",
      "| tcp://172.31.36.220:38213 | 3.7.4.final.0 |\n",
      "| tcp://172.31.43.197:39039 | 3.7.4.final.0 |\n",
      "| tcp://172.31.45.24:40141  | 3.7.4.final.0 |\n",
      "| tcp://172.31.5.106:38861  | 3.7.4.final.0 |\n",
      "| tcp://172.31.53.190:43377 | 3.7.4.final.0 |\n",
      "| tcp://172.31.59.105:38475 | 3.7.4.final.0 |\n",
      "| tcp://172.31.62.163:40761 | 3.7.4.final.0 |\n",
      "| tcp://172.31.67.198:41015 | 3.7.4.final.0 |\n",
      "| tcp://172.31.74.157:46289 | 3.7.4.final.0 |\n",
      "| tcp://172.31.84.201:39471 | 3.7.4.final.0 |\n",
      "| tcp://172.31.87.58:39717  | 3.7.4.final.0 |\n",
      "| tcp://172.31.93.231:36959 | 3.7.4.final.0 |\n",
      "+---------------------------+---------------+\n",
      "\n",
      "tornado\n",
      "+---------------------------+---------+\n",
      "|                           | version |\n",
      "+---------------------------+---------+\n",
      "| client                    | 6.0.3   |\n",
      "| scheduler                 | 6.0.4   |\n",
      "| tcp://172.31.13.44:36759  | 6.0.4   |\n",
      "| tcp://172.31.14.120:36793 | 6.0.4   |\n",
      "| tcp://172.31.18.108:37605 | 6.0.4   |\n",
      "| tcp://172.31.20.181:45127 | 6.0.4   |\n",
      "| tcp://172.31.22.194:40509 | 6.0.4   |\n",
      "| tcp://172.31.32.143:46031 | 6.0.4   |\n",
      "| tcp://172.31.32.54:33291  | 6.0.4   |\n",
      "| tcp://172.31.33.144:43449 | 6.0.4   |\n",
      "| tcp://172.31.36.220:38213 | 6.0.4   |\n",
      "| tcp://172.31.43.197:39039 | 6.0.4   |\n",
      "| tcp://172.31.45.24:40141  | 6.0.4   |\n",
      "| tcp://172.31.5.106:38861  | 6.0.4   |\n",
      "| tcp://172.31.53.190:43377 | 6.0.4   |\n",
      "| tcp://172.31.59.105:38475 | 6.0.4   |\n",
      "| tcp://172.31.62.163:40761 | 6.0.4   |\n",
      "| tcp://172.31.67.198:41015 | 6.0.4   |\n",
      "| tcp://172.31.74.157:46289 | 6.0.4   |\n",
      "| tcp://172.31.84.201:39471 | 6.0.4   |\n",
      "| tcp://172.31.87.58:39717  | 6.0.4   |\n",
      "| tcp://172.31.93.231:36959 | 6.0.4   |\n",
      "+---------------------------+---------+\n",
      "  warnings.warn(version_module.VersionMismatchWarning(msg[0][\"warning\"]))\n"
     ]
    }
   ],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Graphs for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lazy extract Graphs\n",
    "\n",
    "# Function for lazy S3 extraction\n",
    "def load_snapshots(key):\n",
    "    session = boto3.session.Session()\n",
    "    s3 = session.resource('s3')\n",
    "    response = s3.Object(bucket_name='ln-strategy-data', key=key).get()\n",
    "    G=pickle.loads(response['Body'].read())\n",
    "    \n",
    "    return G\n",
    "    \n",
    "# Script to create delayed array\n",
    "graph_snapshots=[]\n",
    "blocks=[]\n",
    "\n",
    "for key in graph_keys[700:1000]: # Remove index for full range\n",
    "    # Create block list from file_names\n",
    "    block_i=int(key.split(\".\")[0].split(\"/\")[-1]) \n",
    "    blocks.append(block_i)\n",
    "    \n",
    "    # Extract graphs\n",
    "    G=dask.delayed(load_snapshots)(key)\n",
    "    graph_snapshots.append(G)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Lazy Graph extract\n",
    "graph_i=dask.compute(graph_snapshots[0])[0]\n",
    "block=graph_i.graph['block']\n",
    "print(type(block))\n",
    "\n",
    "#graph_snapshots=dask.compute(*graph_snapshots)\n",
    "#block=graph_snapshots[0].graph['block']\n",
    "    \n",
    "#print(len(graph_snapshots[5]))\n",
    "#print(graph_snapshots[3].graph['block'])\n",
    "\n",
    "# Delayed testing\n",
    "#results = dask.compute(*futures)\n",
    "#graphs=dask.compute(*graph_snapshots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability/Efficiency analysis by utility definition\n",
    "\n",
    "In order to understand the potential motivations behind each decision we analyze each decission (opening or closure of a channel) independently from the perspective of each of the participants in the decission, which we'll call the node under analysis. For each decission we extract or compute the following information: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Betweeness\n",
    "\n",
    "\n",
    "Betweenness centrality measures how central is a network to the flow of information in a network. In the case of the Lightning Network the higher the betweenness centrality of a node, the more transactions (messages) that are routed through it. In particular, we will use a measure of betweenness centrality defined in (Brandes and Fleischer 2005 - https://link.springer.com/chapter/10.1007/978-3-540-31856-9_44) that models infomation through a network, as electric current, efficiently and not only considering shortest path. This allows us to account for the fact that not all transactions travel through shortes path given that there are fee and capacity considerations.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline betweeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test networkx (sequential computation)\n",
    "\n",
    "snapshot_bet_list=[]\n",
    "\n",
    "def bet_cent(g):\n",
    "    #if len(g)>2:\n",
    "    g_bet=nx.algorithms.centrality.approximate_current_flow_betweenness_centrality(g,weight='capacity',kmax=10000)\n",
    "    block=g.graph['block']\n",
    "    #else:\n",
    "    #g_bet={}\n",
    "    return (block,g_bet)\n",
    "    \n",
    "\n",
    "for g in graph_snapshots:\n",
    "    block_bet_tuple=dask.delayed(bet_cent)(g)\n",
    "    snapshot_bet_list.append(block_bet_tuple)\n",
    "\n",
    "futures_bet = dask.persist(*snapshot_bet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "snapshot_bet_list = dask.compute(*futures_bet)\n",
    "end=time.time()\n",
    "print('Compute in seconds: {}'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary \n",
    "snapshot_bet={record[0]:record[1] for record in snapshot_bet_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test results and size of betweeness in memory\n",
    "# Create list with graph keys\n",
    "print(sys.getsizeof(snapshot_bet))\n",
    "n_items = take(10, snapshot_bet.items())\n",
    "print(n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[505149,\n",
       " 506402,\n",
       " 506847,\n",
       " 508075,\n",
       " 508090,\n",
       " 508320,\n",
       " 508400,\n",
       " 508447,\n",
       " 508503,\n",
       " 508666]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise stability \n",
    "\n",
    "- **Marginal betweenness (bet_mar_nodei)**: The % change between the betweenness centrality, for the node under analysis, given the graph from the previous block and the betweenness centrality of the resulting graph after enacting the decission (adding or removing a channel). Weighted current betweenness centrality is used for this measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------STABILITY FOR OPENS----\n",
    "\n",
    "# Function to calculate marginal betweenness centrality for all channel openings in snapshot\n",
    "\n",
    "def bet_mar_open(input_tuple):\n",
    "    \n",
    "    block=input_tuple[0]\n",
    "    G=input_tuple[1]\n",
    "    block_opens=input_tuple[2]\n",
    "    G_bets=input_tuple[3]\n",
    "    #snapshot_bet=input_tuple[2] - Don't calculate difference\n",
    "    \n",
    "    # For each snapshot get all OPENS. \n",
    "    #block_opens=channel_opens[block]\n",
    "    \n",
    "\n",
    "    # For each open calculate marginal betweenness for each node in channel\n",
    "    \n",
    "    \n",
    "    bet_mar_node0_dic_i={} #Dictionary to store marginal betweeness centrality for node0\n",
    "    bet_mar_node1_dic_i={} #Dictionary to store marginal betweeness centrality for node0\n",
    "    for open_edge in block_opens:\n",
    "        \n",
    "        # Extract info about channel\n",
    "        channel_id=open_edge[2]['channel_id']\n",
    "        node0=open_edge[0]\n",
    "        node1=open_edge[1]\n",
    "        edge_list=[open_edge]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Â Copy original graph\n",
    "        g_mar=G.copy()   \n",
    "        old_nodes=False\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Retrieve betweenness for snapshot if nodes existed\n",
    "        if (g_mar.has_node(node0)):\n",
    "            node0_bet=G_bets[node0]\n",
    "            old_nodes=True\n",
    "            \n",
    "        if (g_mar.has_node(node1)):\n",
    "            node1_bet=G_bets[node1]\n",
    "            old_nodes=True\n",
    "            \n",
    "            \n",
    "        # Add edges and calculate betweeness if at least one of the nodes is in graph \n",
    "        \n",
    "        if old_nodes: \n",
    "            g_mar.add_edges_from(edge_list)\n",
    "            g_mar_bet=nx.algorithms.centrality.approximate_current_flow_betweenness_centrality(g_mar,weight='capacity',kmax=10000)\n",
    "            node0_mar_bet=(g_mar_bet[node0]-node0_bet)\n",
    "            node1_mar_bet=(g_mar_bet[node1]-node1_bet)\n",
    "        else: # Make betweenness -10 if connection is outside of connected graph (both nodes are new)\n",
    "            node0_mar_bet=-10\n",
    "            node1_mar_bet=-10\n",
    "        \n",
    "        # Update dictionary - new betweenness\n",
    "        bet_mar_node0_dic_i[channel_id]=node0_mar_bet\n",
    "        bet_mar_node1_dic_i[channel_id]=node1_mar_bet\n",
    "        \n",
    "    \n",
    "    return (bet_mar_node0_dic_i,bet_mar_node1_dic_i)\n",
    "    \n",
    "\n",
    "# Script to parallelize bet_mar_open\n",
    "\n",
    "bet_mar_dicfut=[]\n",
    "for i in range(len(graph_snapshots)):\n",
    "    \n",
    "    block=blocks[i]\n",
    "    block_opens=channel_opens[block]\n",
    "    #print((block_opens))\n",
    "    g=graph_snapshots[i]\n",
    "    g_bet=snapshot_bet[block]\n",
    "    input_tuple=(block,g,block_opens,g_bet)\n",
    "    output_tuple=dask.delayed(bet_mar_open)(input_tuple)\n",
    "    bet_mar_dicfut.append(output_tuple)\n",
    "\n",
    "futures_bet_mar = dask.persist(*bet_mar_dicfut)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute in seconds: 15.94914698600769\n",
      "Size in memory: 2448\n"
     ]
    }
   ],
   "source": [
    "# Run computation\n",
    "start=time.time()\n",
    "bet_mar_diclist = dask.compute(*futures_bet_mar)\n",
    "end=time.time()\n",
    "print('Compute in seconds: {}'.format(end-start))\n",
    "print('Size in memory: {}'.format(sys.getsizeof(bet_mar_diclist)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'526185x211x1': 0.05827316656294271, '526185x870x1': 0.02219399676110155}, {'526185x211x1': 4.185339268785951e-15, '526185x870x1': -0.00011371264886930049})\n"
     ]
    }
   ],
   "source": [
    "# Test output\n",
    "print(bet_mar_diclist[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create single dictionaries for node0 and node1\n",
    "\n",
    "bet_mar_node0_list=[t[0] for t in bet_mar_diclist]\n",
    "bet_mar_node1_list=[t[1] for t in bet_mar_diclist]\n",
    "\n",
    "bet_mar_node0_dic={}\n",
    "for d in bet_mar_node0_list:\n",
    "    bet_mar_node0_dic.update(d)\n",
    "    \n",
    "bet_mar_node1_dic={}\n",
    "for d in bet_mar_node1_list:\n",
    "    bet_mar_node1_dic.update(d)\n",
    "\n",
    "# Test output\n",
    "# print(bet_mar_node1_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348\n"
     ]
    }
   ],
   "source": [
    "# Add to DataFrame\n",
    "\n",
    "# Create empty columns\n",
    "decisions_df['bet_mar_node0']=np.nan\n",
    "decisions_df['bet_mar_node1']=np.nan\n",
    "\n",
    "# Populate df with values\n",
    "decisions_df['bet_mar_node0']=decisions_df['short_channel_id'].map(bet_mar_node0_dic)\n",
    "decisions_df['bet_mar_node1']=decisions_df['short_channel_id'].map(bet_mar_node1_dic)\n",
    "\n",
    "decisions_df_filter=decisions_df[decisions_df['bet_mar_node0'].notnull()]\n",
    "print(len(decisions_df_filter))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Why is length of Dataframe longer thatn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- **Actual % change in betweenness (bet_act_deltai)**: The % change between the betweenness centrality, for the node under analysis, given the graph from the previous block and the betweenness centrality of the resulting graph after enacting **all** the decissions (adding or removing a channels) in the current block. Weighted current betweenness centrality is used for this measure.\n",
    "\n",
    "- **Marginal betweeness pairwise stability (bet_mar_pairstab)**: Evaluates if given the marginal graph that results from just enacting this decission is consistent with pairwise stability, from a betweenness perspective.\n",
    "\n",
    "- **Actual betweeness pairwise stability (bet_act_pairstab)**: Evaluates if given the marginal graph that results from all the decisions in the block is consitend with pairwise stability, from a betweenness perspective. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Nash stability \n",
    "\n",
    "- **% Change with respect to not making decision (bet_binstat_deltai)**: The % change in betwewnness centrality, for the node under analysis, given the resulting graph after all of the decissions have been executed. \n",
    "- **Nash compatible - binary strategy (bet_binstat_nash)**: Returns true if given the other decissions enacted in the block not making decision would have NOT have resulted in higher betweenness centrality. This tells me if my strategy helped me be better off (took into account what others were doing)\n",
    "\n",
    "(Optional approaches - Check for tracktability)\n",
    "- **Nash compatible - close only strategy (bet_closestat_nash)**: Returns true if given the other decissions enacted in the block, closing any other channels would NOT have not resulted in higher betwneenness centrality. (NOTE: Check if there are combinatorial considerations, if so just look at closings up to x) \n",
    "- **Nash compatible - close/open (bet_allstat_nash)**: Returns true if given the other decissions enacted in the block, closing any other channels (with any node) or opening a channel with one of the round participants would NOT have not resulted in lower betwneenness centrality. (NOTE: To make it reasonable and constraint the strategy space only consider 'similar nodes' or with relationships in the past?).\n",
    "\n",
    "\n",
    "\n",
    "### Efficiency\n",
    "- **Average betweeness per block (bet_effic)**: Average betweenness centrality for all the nodes. \n",
    "\n",
    "\n",
    "\n",
    "## Connectivity\n",
    "\n",
    "### Pairwise stability \n",
    "\n",
    "- **Marginal % change in connectivity (con_mar_deltai)**: The % change between the shortest path average, for the node under analysis, given the graph from the previous block and the shortest path average of the resulting graph after enacting the decission (adding or removing a channel). Weighted shortest path (_single_source_dijkstra_path_) is used for this measure.\n",
    "\n",
    "- **Actual % change in connectivity (con_act_deltai)**: The % change between the shortest path average, for the node under analysis, given the graph from the previous block and the shortest path average of the resulting graph after enacting **all** the decissions (adding or removing a channels) in the current block. Weighted shortest path (_single_source_dijkstra_path_) is used for this measure.\n",
    "\n",
    "- **Marginal connectivity pairwise stability (con_mar_pairstab)**: Evaluates if given the marginal graph that results from just enacting this decission is consistent with pairwise stability, from a connectivity perspective.\n",
    "\n",
    "- **Actual connectivity pairwise stability (con_act_pairstab)**: Evaluates if given the marginal graph that results from all the decisions in the block is consitend with pairwise stability, from a connectivity perspective.  \n",
    "\n",
    "\n",
    "\n",
    "### Nash stability \n",
    "\n",
    "- **% Change with respect to not making decision (con_binstat_deltai)**: The % change in shortest path average, for the node under analysis, given the resulting graph after all of the decissions have been executed. \n",
    "- **Nash compatible - binary strategy (con_binstat_nash)**: Returns true if given the other decissions enacted in the block not making decision would have NOT have resulted in higher shortest path average. NOTE: This indicates if the strategy selected made the node better off (took into account what others were doing)\n",
    "\n",
    "(Optional approaches - Check for tracktability)\n",
    "- **Nash compatible - close only strategy (con_closestat_nash)**: Returns true if given the other decissions enacted in the block, closing any other channels would NOT have not resulted in higher shortest path average. (NOTE: Check if there are combinatorial considerations, if so just look at closings up to x) \n",
    "- **Nash compatible - close/open (con_allstat_nash)**: Returns true if given the other decissions enacted in the block, closing any other channels (with any node) or opening a channel with one of the round participants would NOT have not resulted in lower shortest path average. (NOTE: To make it reasonable and constraint the strategy space only consider 'similar nodes' or with relationships in the past?).\n",
    "\n",
    "\n",
    "\n",
    "### Efficiency\n",
    "- **Average betweeness per block (bet_effic)**: Average shortest path average for all the nodes. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
